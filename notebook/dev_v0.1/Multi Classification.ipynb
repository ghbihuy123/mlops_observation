{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HuyLQ15_CTV\\Desktop\\model_monitoring\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "data = load_iris(as_frame=True)['data']\n",
    "data = shuffle(data, random_state=42)\n",
    "data['target'] = load_iris(as_frame=True)['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "X = data.drop('target', axis=1).iloc[:125]\n",
    "y = data['target'].iloc[:125]\n",
    "model = LogisticRegression()\n",
    "model.fit(X, y)\n",
    "prediction1 = model.predict(data.drop('target', axis=1))\n",
    "prediction2 = model.predict_proba(data.drop('target', axis=1))\n",
    "data['prediction'] = prediction1\n",
    "data[['0','1','2']] = prediction2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data2 = pd.DataFrame(prediction2, columns=model.classes_)\n",
    "data2['target'] = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference = data.iloc[:75]\n",
    "current = data.iloc[75:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels=['0','1','2']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kế hoạch\n",
    "Có 2 option để truyền vào column mapping\n",
    "- Kết quả dạng đã chuyển thành predict label\n",
    "- Kết quả dạng xác suất\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformed labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.base_metric import MetricResult, InputData\n",
    "\n",
    "from typing import Optional\n",
    "class MultiClassificationResult(MetricResult):\n",
    "    class Config:\n",
    "        type_alias = \"evidently:metric_result:MultiClassificationResult\"\n",
    "    accuracy: float\n",
    "    confusion_matrix: dict\n",
    "    classification_info: dict\n",
    "    logloss: Optional[float]\n",
    "    roc_auc: Optional[dict]\n",
    "    mattheus_corr_coefficient: float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.metrics import matthews_corrcoef\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "from source.calculator.classification_performance import calculate_confusion_by_classes \n",
    "from sklearn.metrics import confusion_matrix\n",
    "def calculate_confusion_matrix_by_classes(y_true, y_pred):\n",
    "    labels = list(set(y_true) | set(y_pred))\n",
    "    confusion_matrix_inf = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    return calculate_confusion_by_classes(confusion_matrix_inf, class_names=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_multi_classification(\n",
    "    prediction: pd.Series, \n",
    "    target: pd.Series,\n",
    "    prediction_proba: pd.DataFrame = None\n",
    "    ) -> MultiClassificationResult:\n",
    "\n",
    "    prediction = prediction.map(str)\n",
    "    target = target.map(str)\n",
    "\n",
    "    logloss = None\n",
    "    roc_auc = None\n",
    "    \n",
    "    accuracy = accuracy_score(target, prediction)\n",
    "    classification_info = classification_report(target, prediction, output_dict=True)\n",
    "    classification_info.pop('accuracy')\n",
    "    confusion_matrix = calculate_confusion_matrix_by_classes(target, prediction)\n",
    "    mattheus_corr_coefficient = matthews_corrcoef(target, prediction)\n",
    "    if prediction_proba is not None:\n",
    "        try:\n",
    "            roc_auc = {}\n",
    "            roc_auc['ovr'] = float(roc_auc_score(y_true=prediction, y_score=prediction_proba, multi_class='ovr'))\n",
    "            roc_auc['ovo'] = float(roc_auc_score(y_true=prediction, y_score=prediction_proba, multi_class='ovo'))\n",
    "            logloss = log_loss(y_true=prediction, y_pred=prediction_proba)\n",
    "        except:\n",
    "            pass\n",
    "    return MultiClassificationResult(\n",
    "        accuracy = accuracy,\n",
    "        confusion_matrix = confusion_matrix,\n",
    "        classification_info = classification_info,\n",
    "        logloss = logloss,\n",
    "        roc_auc = roc_auc,\n",
    "        mattheus_corr_coefficient = float(mattheus_corr_coefficient)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiClassificationResult(type='evidently:metric_result:MultiClassificationResult', accuracy=0.96, confusion_matrix={'0': {'tp': 50.0, 'tn': 100.0, 'fp': 0.0, 'fn': 0.0}, '1': {'tp': 48.0, 'tn': 96.0, 'fp': 4.0, 'fn': 2.0}, '2': {'tp': 46.0, 'tn': 98.0, 'fp': 2.0, 'fn': 4.0}}, classification_info={'0': {'precision': 1.0, 'recall': 1.0, 'f1-score': 1.0, 'support': 50.0}, '1': {'precision': 0.9230769230769231, 'recall': 0.96, 'f1-score': 0.9411764705882353, 'support': 50.0}, '2': {'precision': 0.9583333333333334, 'recall': 0.92, 'f1-score': 0.9387755102040817, 'support': 50.0}, 'macro avg': {'precision': 0.9604700854700855, 'recall': 0.96, 'f1-score': 0.9599839935974389, 'support': 150.0}, 'weighted avg': {'precision': 0.9604700854700855, 'recall': 0.96, 'f1-score': 0.9599839935974391, 'support': 150.0}}, logloss=0.12454405235626946, roc_auc={'ovr': 1.0, 'ovo': 1.0}, mattheus_corr_coefficient=0.9402507669779171)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evidently.pipeline.column_mapping import ColumnMapping\n",
    "from evidently.utils.data_operations import process_columns\n",
    "from evidently.calculations.classification_performance import get_prediction_data\n",
    "\n",
    "column_mapping = ColumnMapping()\n",
    "column_mapping.prediction = ['0','1','2']\n",
    "column_mapping.target = 'target'\n",
    "\n",
    "\n",
    "dataset_column = process_columns(data, column_mapping)\n",
    "prediction_data = get_prediction_data(data, data_columns=dataset_column, pos_label=None, threshold = 0.5)\n",
    "\n",
    "results = calculate_multi_classification(\n",
    "    prediction=prediction_data.predictions,\n",
    "    target=data['target'],\n",
    "    prediction_proba=prediction_data.prediction_probas\n",
    ")\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.base_metric import Metric\n",
    "class MultiClassificationPerformanceResult(MetricResult):\n",
    "    class Config:\n",
    "        type_alias = \"evidently:metric_result:MultiClassificationPerformanceResult\"\n",
    "    reference: Optional[MultiClassificationResult]\n",
    "    current: MultiClassificationResult\n",
    "\n",
    "class MultiClassificationPerformanceMetric(Metric[MultiClassificationPerformanceResult]):\n",
    "    class Config:\n",
    "        type_alias = \"evidently:metric:MultiClassificationPerformanceMetric\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def calculate(self, data: InputData) -> MultiClassificationPerformanceResult:\n",
    "        results = {}\n",
    "        results['reference'] = None\n",
    "        if data.current_data is None:\n",
    "            raise ValueError(\"The value cannot be None\")\n",
    "\n",
    "        if data.reference_data is not None:\n",
    "            results['reference'] = self.get_classification_result(data.reference_data, data.column_mapping)\n",
    "            \n",
    "        results['current'] = self.get_classification_result(data.current_data, data.column_mapping)\n",
    "        return MultiClassificationPerformanceResult(\n",
    "            reference=results['reference'],\n",
    "            current=results['current']\n",
    "        )\n",
    "        \n",
    "    def get_classification_result(self, data: pd.DataFrame, column_mapping: ColumnMapping) -> MultiClassificationResult:\n",
    "        dataset_column = process_columns(data, column_mapping)\n",
    "        prediction_data = get_prediction_data(data, data_columns=dataset_column, pos_label=None, threshold = 0.5)\n",
    "        results = calculate_multi_classification(\n",
    "            prediction=prediction_data.predictions,\n",
    "            target=data[dataset_column.utility_columns.target],\n",
    "            prediction_proba=prediction_data.prediction_probas\n",
    "        )\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.renderers.base_renderer import MetricRenderer, default_renderer\n",
    "\n",
    "@default_renderer(wrap_type=MultiClassificationPerformanceMetric)\n",
    "class MultiClassificationPerformanceRender(MetricRenderer):\n",
    "    def render_json(self, obj: MultiClassificationPerformanceMetric, include_render: bool = False,\n",
    "        include: \"IncludeOptions\" = None, exclude: \"IncludeOptions\" = None,) -> dict:\n",
    "        result = obj.get_result().get_dict(include_render, include, exclude)\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"version\": \"0.4.39\", \"metrics\": [{\"metric\": \"MultiClassificationPerformanceMetric\", \"result\": {\"reference\": {\"accuracy\": 0.9733333333333334, \"confusion_matrix\": {\"0\": {\"tp\": 29.0, \"tn\": 46.0, \"fp\": 0.0, \"fn\": 0.0}, \"1\": {\"tp\": 23.0, \"tn\": 50.0, \"fp\": 2.0, \"fn\": 0.0}, \"2\": {\"tp\": 21.0, \"tn\": 52.0, \"fp\": 0.0, \"fn\": 2.0}}, \"classification_info\": {\"0\": {\"precision\": 1.0, \"recall\": 1.0, \"f1-score\": 1.0, \"support\": 29.0}, \"1\": {\"precision\": 0.92, \"recall\": 1.0, \"f1-score\": 0.9583333333333334, \"support\": 23.0}, \"2\": {\"precision\": 1.0, \"recall\": 0.9130434782608695, \"f1-score\": 0.9545454545454546, \"support\": 23.0}, \"macro avg\": {\"precision\": 0.9733333333333333, \"recall\": 0.9710144927536232, \"f1-score\": 0.970959595959596, \"support\": 75.0}, \"weighted avg\": {\"precision\": 0.9754666666666666, \"recall\": 0.9733333333333334, \"f1-score\": 0.9732828282828283, \"support\": 75.0}}, \"logloss\": 0.11196622485325247, \"roc_auc\": {\"ovr\": 1.0, \"ovo\": 1.0}, \"mattheus_corr_coefficient\": 0.9607743323674646}, \"current\": {\"accuracy\": 0.9733333333333334, \"confusion_matrix\": {\"0\": {\"tp\": 29.0, \"tn\": 46.0, \"fp\": 0.0, \"fn\": 0.0}, \"1\": {\"tp\": 23.0, \"tn\": 50.0, \"fp\": 2.0, \"fn\": 0.0}, \"2\": {\"tp\": 21.0, \"tn\": 52.0, \"fp\": 0.0, \"fn\": 2.0}}, \"classification_info\": {\"0\": {\"precision\": 1.0, \"recall\": 1.0, \"f1-score\": 1.0, \"support\": 29.0}, \"1\": {\"precision\": 0.92, \"recall\": 1.0, \"f1-score\": 0.9583333333333334, \"support\": 23.0}, \"2\": {\"precision\": 1.0, \"recall\": 0.9130434782608695, \"f1-score\": 0.9545454545454546, \"support\": 23.0}, \"macro avg\": {\"precision\": 0.9733333333333333, \"recall\": 0.9710144927536232, \"f1-score\": 0.970959595959596, \"support\": 75.0}, \"weighted avg\": {\"precision\": 0.9754666666666666, \"recall\": 0.9733333333333334, \"f1-score\": 0.9732828282828283, \"support\": 75.0}}, \"logloss\": 0.11196622485325247, \"roc_auc\": {\"ovr\": 1.0, \"ovo\": 1.0}, \"mattheus_corr_coefficient\": 0.9607743323674646}}}], \"timestamp\": \"2024-11-28 16:29:52.101122\"}'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from evidently.report import Report\n",
    "\n",
    "report = Report(metrics=[\n",
    "    MultiClassificationPerformanceMetric()\n",
    "])\n",
    "\n",
    "report.run(current_data=reference, reference_data=reference, column_mapping=column_mapping)\n",
    "report.json()\n",
    "# report.save_json('./reports/custom/Multi Classification Performance.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HuyLQ15_CTV\\AppData\\Local\\miniconda3\\envs\\model-monitoring\\lib\\site-packages\\evidently\\pydantic_utils.py:161: UserWarning: Duplicate key (<class 'evidently.base_metric.Metric'>, 'evidently:metric:RegressionPerformanceMetrics') in alias map\n",
      "  warnings.warn(f\"Duplicate key {key} in alias map\")\n",
      "c:\\Users\\HuyLQ15_CTV\\AppData\\Local\\miniconda3\\envs\\model-monitoring\\lib\\site-packages\\evidently\\pydantic_utils.py:161: UserWarning: Duplicate key (<class 'evidently.base_metric.MetricResult'>, 'evidently:metric_result:MultiClassificationResult') in alias map\n",
      "  warnings.warn(f\"Duplicate key {key} in alias map\")\n",
      "c:\\Users\\HuyLQ15_CTV\\AppData\\Local\\miniconda3\\envs\\model-monitoring\\lib\\site-packages\\evidently\\pydantic_utils.py:161: UserWarning: Duplicate key (<class 'evidently.base_metric.MetricResult'>, 'evidently:metric_result:MultiClassificationPerformanceResult') in alias map\n",
      "  warnings.warn(f\"Duplicate key {key} in alias map\")\n",
      "c:\\Users\\HuyLQ15_CTV\\AppData\\Local\\miniconda3\\envs\\model-monitoring\\lib\\site-packages\\evidently\\pydantic_utils.py:161: UserWarning: Duplicate key (<class 'evidently.base_metric.Metric'>, 'evidently:metric:MultiClassificationPerformanceMetric') in alias map\n",
      "  warnings.warn(f\"Duplicate key {key} in alias map\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'{\"version\": \"0.4.39\", \"metrics\": [{\"metric\": \"MultiClassificationPerformanceMetric\", \"result\": {\"reference\": {\"accuracy\": 0.9733333333333334, \"confusion_matrix\": {\"0\": {\"tp\": 29.0, \"tn\": 46.0, \"fp\": 0.0, \"fn\": 0.0}, \"1\": {\"tp\": 23.0, \"tn\": 50.0, \"fp\": 2.0, \"fn\": 0.0}, \"2\": {\"tp\": 21.0, \"tn\": 52.0, \"fp\": 0.0, \"fn\": 2.0}}, \"classification_info\": {\"0\": {\"precision\": 1.0, \"recall\": 1.0, \"f1-score\": 1.0, \"support\": 29.0}, \"1\": {\"precision\": 0.92, \"recall\": 1.0, \"f1-score\": 0.9583333333333334, \"support\": 23.0}, \"2\": {\"precision\": 1.0, \"recall\": 0.9130434782608695, \"f1-score\": 0.9545454545454546, \"support\": 23.0}, \"macro avg\": {\"precision\": 0.9733333333333333, \"recall\": 0.9710144927536232, \"f1-score\": 0.970959595959596, \"support\": 75.0}, \"weighted avg\": {\"precision\": 0.9754666666666666, \"recall\": 0.9733333333333334, \"f1-score\": 0.9732828282828283, \"support\": 75.0}}, \"logloss\": 0.11215725602203173, \"roc_auc\": {\"ovr\": 1.0, \"ovo\": 1.0}, \"mattheus_corr_coefficient\": 0.9607743323674646}, \"current\": {\"accuracy\": 0.9466666666666667, \"confusion_matrix\": {\"0\": {\"tp\": 21.0, \"tn\": 54.0, \"fp\": 0.0, \"fn\": 0.0}, \"1\": {\"tp\": 25.0, \"tn\": 46.0, \"fp\": 2.0, \"fn\": 2.0}, \"2\": {\"tp\": 25.0, \"tn\": 46.0, \"fp\": 2.0, \"fn\": 2.0}}, \"classification_info\": {\"0\": {\"precision\": 1.0, \"recall\": 1.0, \"f1-score\": 1.0, \"support\": 21.0}, \"1\": {\"precision\": 0.9259259259259259, \"recall\": 0.9259259259259259, \"f1-score\": 0.9259259259259259, \"support\": 27.0}, \"2\": {\"precision\": 0.9259259259259259, \"recall\": 0.9259259259259259, \"f1-score\": 0.9259259259259259, \"support\": 27.0}, \"macro avg\": {\"precision\": 0.9506172839506174, \"recall\": 0.9506172839506174, \"f1-score\": 0.9506172839506174, \"support\": 75.0}, \"weighted avg\": {\"precision\": 0.9466666666666667, \"recall\": 0.9466666666666667, \"f1-score\": 0.9466666666666667, \"support\": 75.0}}, \"logloss\": 0.15430911691887317, \"roc_auc\": {\"ovr\": 0.9953703703703703, \"ovo\": 0.9958847736625515}, \"mattheus_corr_coefficient\": 0.9194847020933977}}}], \"timestamp\": \"2024-11-28 16:29:52.388962\"}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from source.metrics import MultiClassificationPerformanceMetric\n",
    "report = Report(metrics=[\n",
    "    MultiClassificationPerformanceMetric()\n",
    "])\n",
    "\n",
    "report.run(current_data=current, reference_data=reference, column_mapping=column_mapping)\n",
    "report.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.metrics import ConflictPredictionMetric\n",
    "from evidently.metrics import ClassificationQualityMetric\n",
    "from evidently.metrics import ClassificationClassBalance\n",
    "from evidently.metrics import ClassificationConfusionMatrix\n",
    "from evidently.metrics import ClassificationQualityByClass\n",
    "from evidently.metrics import ClassificationClassSeparationPlot\n",
    "from evidently.metrics import ClassificationProbDistribution\n",
    "from evidently.metrics import ClassificationRocCurve\n",
    "from evidently.metrics import ClassificationPRCurve\n",
    "from evidently.metrics import ClassificationPRTable\n",
    "from evidently.metrics import ClassificationLiftCurve\n",
    "from evidently.report import Report\n",
    "\n",
    "classification_report = Report(metrics=[\n",
    "    ClassificationQualityMetric(),\n",
    "    ClassificationClassBalance(),\n",
    "    ClassificationConfusionMatrix(),\n",
    "    ClassificationQualityByClass(),\n",
    "    # ClassificationRocCurve(),\n",
    "    # ClassificationPRCurve(),\n",
    "    # ClassificationLiftCurve(),\n",
    "])\n",
    "\n",
    "classification_report.run(reference_data=reference, current_data=current)\n",
    "classification_report.save_html(\"./reports/default/classification_report.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HuyLQ15_CTV\\AppData\\Local\\miniconda3\\envs\\model-monitoring\\lib\\site-packages\\evidently\\pydantic_utils.py:161: UserWarning:\n",
      "\n",
      "Duplicate key (<class 'evidently.metric_preset.metric_preset.MetricPreset'>, 'evidently:metric_preset:DataDriftPreset') in alias map\n",
      "\n",
      "c:\\Users\\HuyLQ15_CTV\\AppData\\Local\\miniconda3\\envs\\model-monitoring\\lib\\site-packages\\evidently\\pydantic_utils.py:161: UserWarning:\n",
      "\n",
      "Duplicate key (<class 'evidently.metric_preset.metric_preset.MetricPreset'>, 'evidently:metric_preset:DataQualityPreset') in alias map\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from source.metric_preset.multi_classification import MultiClassificationPreset\n",
    "\n",
    "classification_report = Report(metrics=[\n",
    "    MultiClassificationPreset()\n",
    "])\n",
    "\n",
    "classification_report.run(reference_data=reference, current_data=current)\n",
    "classification_report.save_html(\"./reports/custom/Classification Report.html\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "207e60eac2ff56558166198e2c0941ea4216ea025c42ddd95d3a76ed9cb3f5a9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.15 ('model-monitoring')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
