{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HuyLQ15_CTV\\Desktop\\model_monitoring\n"
     ]
    }
   ],
   "source": [
    "%cd ../.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HuyLQ15_CTV\\AppData\\Local\\miniconda3\\envs\\model-monitoring\\lib\\site-packages\\urllib3\\connectionpool.py:1099: InsecureRequestWarning: Unverified HTTPS request is being made to host 'ho-proxy02.tpb.vn'. Adding certificate verification is strongly advised. See: https://urllib3.readthedocs.io/en/latest/advanced-usage.html#tls-warnings\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from datetime import time, datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import zipfile\n",
    "import io\n",
    "from datetime import datetime, time\n",
    "from source.mlops_observation import ColumnMapping\n",
    "\n",
    "content = requests.get(\"https://archive.ics.uci.edu/static/public/275/bike+sharing+dataset.zip\", verify=False).content\n",
    "with zipfile.ZipFile(io.BytesIO(content)) as arc:\n",
    "    raw_data = pd.read_csv(arc.open(\"hour.csv\"), header=0, sep=',', parse_dates=['dteday'], index_col='dteday')\n",
    "raw_data.index = raw_data.apply(\n",
    "    lambda row: datetime.combine(row.name, time(hour=int(row['hr']))), axis = 1)\n",
    "target = 'cnt'\n",
    "prediction = 'prediction'\n",
    "numerical_features = ['temp', 'atemp', 'hum', 'windspeed', 'hr', 'weekday']\n",
    "categorical_features = ['season', 'holiday', 'workingday']\n",
    "column_mapping = ColumnMapping()\n",
    "column_mapping.numerical_features = numerical_features\n",
    "column_mapping.categorical_features = categorical_features\n",
    "\n",
    "reference = raw_data.loc['2011-01-01 00:00:00':'2011-01-31 00:00:00']\n",
    "current = raw_data.loc['2011-02-01 00:00:00':'2011-07-28 23:00:00']\n",
    "current['time_stamp'] = current.index\n",
    "reference['time_stamp'] = reference.index\n",
    "column_mapping.datetime_features = 'time_stamp'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Period Data Quality Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from typing import Dict\n",
    "\n",
    "# def dataset_summary_to_dataframe(dataset: pd.DataFrame, column_mapping: ColumnMapping, period: str='M') -> pd.DataFrame:\n",
    "#     \"\"\"\n",
    "#     Convert a dictionary of DatasetSummary objects into a DataFrame.\n",
    "\n",
    "#     Parameters:\n",
    "#     - dataset: pd.DataFrame\n",
    "#         Dataset to be calculated the summary stats\n",
    "#     - column_mapping: ColumnMapping\n",
    "#     - period: str\n",
    "\n",
    "#     Returns:\n",
    "#     - pd.DataFrame: A DataFrame with dates as columns and DatasetSummary attributes as index.\n",
    "#     \"\"\"\n",
    "#     dataset_summary_dict = {}             # Dict[str, DatasetSummary]\n",
    "#     data_period_dict = divide_into_chunks_by_period(dataset, column_mapping.datetime_features, period=period)\n",
    "#     for data_date in data_period_dict.keys():\n",
    "#         dataset_summary_dict[data_date] = calculate_dataset_common_stats(data_period_dict[data_date], column_mapping)\n",
    "#     data = {}\n",
    "\n",
    "#     for date, summary in dataset_summary_dict.items():\n",
    "#         # Convert the DatasetSummary object to a dictionary\n",
    "#         summary_dict = summary.__dict__\n",
    "        \n",
    "#         # Remove \"number_uniques_by_columns\" \n",
    "#         summary_dict.pop('number_uniques_by_columns', None)\n",
    "#         summary_dict.pop('nans_by_columns', None)\n",
    "\n",
    "#         # Add the data for this date\n",
    "#         data[date] = summary_dict\n",
    "#     df = pd.DataFrame(data).reset_index()\n",
    "#     df.rename(columns={'index': ''}, inplace=True)\n",
    "#     return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df1 = dataset_summary_to_dataframe(current, column_mapping)\n",
    "# df2 = dataset_summary_to_dataframe(reference, column_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.merge(df2, df1, on='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# from typing import Optional, Dict, List\n",
    "# from evidently.model.widget import BaseWidgetInfo\n",
    "# from evidently.base_metric import MetricResult, Metric, InputData\n",
    "# from evidently.model.widget import BaseWidgetInfo\n",
    "# from evidently.base_metric import InputData, Metric, MetricResult\n",
    "# from evidently import ColumnMapping\n",
    "# from evidently.renderers.base_renderer import default_renderer\n",
    "# from evidently.renderers.base_renderer import MetricRenderer\n",
    "# from evidently.utils.visualizations import plot_distr\n",
    "# from evidently.renderers import html_widgets\n",
    "# from evidently.renderers.html_widgets import plotly_data\n",
    "# from evidently.renderers.html_widgets import header_text\n",
    "# from source.mlops_observation.utils.visualization import dataframe_to_widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PeriodDataQuality(MetricResult):\n",
    "#     class Config:\n",
    "#         type_alias = \"evidently:metric_result:PeriodDataQuality\"\n",
    "#     summary_table: Optional[pd.DataFrame]\n",
    "\n",
    "# class PeriodDataQualityMetric(Metric[PeriodDataQuality]):\n",
    "#     \"\"\"\n",
    "#     time_period (str): Offset aliases https://pandas.pydata.org/docs/user_guide/timeseries.html#dateoffset-objects\n",
    "#     \"\"\"\n",
    "#     class Config:\n",
    "#         type_alias = \"evidently:metric:PeriodDataQualityMetric\"\n",
    "#     _time_period: str\n",
    "#     def __init__(self, time_period: str = 'M'):\n",
    "#         self._time_period = time_period\n",
    "#         super().__init__()\n",
    "\n",
    "#     def calculate(self, data: InputData):\n",
    "#         if data.reference_data is None:\n",
    "#             raise ValueError(\"Reference dataset should be present\")\n",
    "#         if data.current_data is None:\n",
    "#             raise ValueError(\"Current dataset should be present\")\n",
    "#         column_mapping = data.column_mapping\n",
    "#         if data.current_data is not None:\n",
    "#             reference_summary_table = self._dataset_summary_to_dataframe(\n",
    "#                 dataset=data.reference_data,\n",
    "#                 column_mapping=column_mapping,\n",
    "#                 period=self._time_period\n",
    "#             )\n",
    "#             reference_summary_table.columns = [reference_summary_table.columns[0]] + [f\"{col} (base)\" for col in reference_summary_table.columns[1:]]\n",
    "#             current_summary_table = self._dataset_summary_to_dataframe(\n",
    "#                 dataset=data.current_data,\n",
    "#                 column_mapping=column_mapping,\n",
    "#                 period=self._time_period\n",
    "#             )\n",
    "#             summary_table = pd.merge(reference_summary_table, current_summary_table, on='')\n",
    "#         else:\n",
    "#             summary_table = self._dataset_summary_to_dataframe(\n",
    "#                 dataset=data.reference_data,\n",
    "#                 column_mapping=column_mapping,\n",
    "#                 period=self._time_period\n",
    "#             )\n",
    "#         return PeriodDataQuality(\n",
    "#             summary_table=summary_table\n",
    "#         )\n",
    "#     def _dataset_summary_to_dataframe(\n",
    "#         self, \n",
    "#         dataset: pd.DataFrame, \n",
    "#         column_mapping: str, \n",
    "#         period: str='M'\n",
    "#         ) -> pd.DataFrame:\n",
    "#         \"\"\"\n",
    "#         Convert a dictionary of DatasetSummary objects into a DataFrame.\n",
    "\n",
    "#         Parameters:\n",
    "#         - dataset_summary_dict: A dictionary where keys are dates (str) and values are DatasetSummary objects.\n",
    "\n",
    "#         Returns:\n",
    "#         - pd.DataFrame: A DataFrame with dates as columns and DatasetSummary attributes as index.\n",
    "#         \"\"\"\n",
    "#         dataset_summary_dict = {}             # Dict[str, DatasetSummary]\n",
    "#         data_period_dict = divide_into_chunks_by_period(dataset, column_mapping.datetime_features, period=period)\n",
    "#         for data_date in data_period_dict.keys():\n",
    "#             dataset_summary_dict[data_date] = calculate_dataset_common_stats(data_period_dict[data_date], column_mapping)\n",
    "#         data = {}\n",
    "\n",
    "#         for date, summary in dataset_summary_dict.items():\n",
    "#             # Convert the DatasetSummary object to a dictionary\n",
    "#             summary_dict = summary.__dict__\n",
    "            \n",
    "#             # Remove \"number_uniques_by_columns\" \n",
    "#             summary_dict.pop('number_uniques_by_columns', None)\n",
    "#             summary_dict.pop('nans_by_columns', None)\n",
    "\n",
    "#             # Add the data for this date\n",
    "#             data[date] = summary_dict\n",
    "#         df = pd.DataFrame(data).reset_index()\n",
    "#         df.rename(columns={'index': ''}, inplace=True)\n",
    "#         return df\n",
    "\n",
    "# @default_renderer(wrap_type=PeriodDataQualityMetric)\n",
    "# class PeriodDataQualityRender(MetricRenderer):\n",
    "#     def render_html(self, obj: PeriodDataQualityMetric) -> List[BaseWidgetInfo]:\n",
    "#         results = obj.get_result()\n",
    "#         color_options = self.color_options\n",
    "#         summary_table = dataframe_to_widget(results.summary_table)\n",
    "#         return [\n",
    "#             header_text(label=f\"Data Quality in period Report\"),\n",
    "#             summary_table\n",
    "#         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from source.mlops_observation import Report\n",
    "# from source.mlops_observation.metrics import PeriodDataQualityMetric\n",
    "# report = Report([PeriodDataQualityMetric(time_period='M')])\n",
    "# report.run(reference_data=reference, current_data=current, column_mapping=column_mapping)\n",
    "# report.save_html('1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# period feature stats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HuyLQ15_CTV\\AppData\\Local\\miniconda3\\envs\\model-monitoring\\lib\\site-packages\\evidently\\pydantic_utils.py:161: UserWarning: Duplicate key (<class 'evidently.base_metric.MetricResult'>, 'evidently:metric_result:DatasetUtilityColumns') in alias map\n",
      "  warnings.warn(f\"Duplicate key {key} in alias map\")\n",
      "c:\\Users\\HuyLQ15_CTV\\AppData\\Local\\miniconda3\\envs\\model-monitoring\\lib\\site-packages\\evidently\\pydantic_utils.py:161: UserWarning: Duplicate key (<class 'evidently.base_metric.MetricResult'>, 'evidently:metric_result:DatasetColumns') in alias map\n",
      "  warnings.warn(f\"Duplicate key {key} in alias map\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'2011-01':                      instant  season  yr  mnth  hr  holiday  weekday  \\\n",
       " 2011-01-01 00:00:00        1       1   0     1   0        0        6   \n",
       " 2011-01-01 01:00:00        2       1   0     1   1        0        6   \n",
       " 2011-01-01 02:00:00        3       1   0     1   2        0        6   \n",
       " 2011-01-01 03:00:00        4       1   0     1   3        0        6   \n",
       " 2011-01-01 04:00:00        5       1   0     1   4        0        6   \n",
       " ...                      ...     ...  ..   ...  ..      ...      ...   \n",
       " 2011-01-30 20:00:00      661       1   0     1  20        0        0   \n",
       " 2011-01-30 21:00:00      662       1   0     1  21        0        0   \n",
       " 2011-01-30 22:00:00      663       1   0     1  22        0        0   \n",
       " 2011-01-30 23:00:00      664       1   0     1  23        0        0   \n",
       " 2011-01-31 00:00:00      665       1   0     1   0        0        1   \n",
       " \n",
       "                      workingday  weathersit  temp   atemp   hum  windspeed  \\\n",
       " 2011-01-01 00:00:00           0           1  0.24  0.2879  0.81     0.0000   \n",
       " 2011-01-01 01:00:00           0           1  0.22  0.2727  0.80     0.0000   \n",
       " 2011-01-01 02:00:00           0           1  0.22  0.2727  0.80     0.0000   \n",
       " 2011-01-01 03:00:00           0           1  0.24  0.2879  0.75     0.0000   \n",
       " 2011-01-01 04:00:00           0           1  0.24  0.2879  0.75     0.0000   \n",
       " ...                         ...         ...   ...     ...   ...        ...   \n",
       " 2011-01-30 20:00:00           0           2  0.26  0.2727  0.65     0.1045   \n",
       " 2011-01-30 21:00:00           0           2  0.24  0.2424  0.70     0.1642   \n",
       " 2011-01-30 22:00:00           0           2  0.24  0.2273  0.70     0.1940   \n",
       " 2011-01-30 23:00:00           0           2  0.24  0.2121  0.65     0.2836   \n",
       " 2011-01-31 00:00:00           1           2  0.24  0.2273  0.65     0.2239   \n",
       " \n",
       "                      casual  registered  cnt          time_stamp  \n",
       " 2011-01-01 00:00:00       3          13   16 2011-01-01 00:00:00  \n",
       " 2011-01-01 01:00:00       8          32   40 2011-01-01 01:00:00  \n",
       " 2011-01-01 02:00:00       5          27   32 2011-01-01 02:00:00  \n",
       " 2011-01-01 03:00:00       3          10   13 2011-01-01 03:00:00  \n",
       " 2011-01-01 04:00:00       0           1    1 2011-01-01 04:00:00  \n",
       " ...                     ...         ...  ...                 ...  \n",
       " 2011-01-30 20:00:00       3          30   33 2011-01-30 20:00:00  \n",
       " 2011-01-30 21:00:00       3          25   28 2011-01-30 21:00:00  \n",
       " 2011-01-30 22:00:00       2          19   21 2011-01-30 22:00:00  \n",
       " 2011-01-30 23:00:00       5          16   21 2011-01-30 23:00:00  \n",
       " 2011-01-31 00:00:00       1           6    7 2011-01-31 00:00:00  \n",
       " \n",
       " [665 rows x 17 columns]}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from source.mlops_observation.utils.data_operations import divide_into_chunks_by_period\n",
    "\n",
    "reference_dict = divide_into_chunks_by_period(reference, time_column=column_mapping.datetime_features, period='M')\n",
    "reference_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "      <th>time_stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "      <td>2011-01-01 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "      <td>2011-01-01 01:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "      <td>2011-01-01 02:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>2011-01-01 03:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01 04:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30 20:00:00</th>\n",
       "      <td>661</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.1045</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>33</td>\n",
       "      <td>2011-01-30 20:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30 21:00:00</th>\n",
       "      <td>662</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2424</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>3</td>\n",
       "      <td>25</td>\n",
       "      <td>28</td>\n",
       "      <td>2011-01-30 21:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30 22:00:00</th>\n",
       "      <td>663</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.1940</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>2011-01-30 22:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-30 23:00:00</th>\n",
       "      <td>664</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2121</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.2836</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>21</td>\n",
       "      <td>2011-01-30 23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-31 00:00:00</th>\n",
       "      <td>665</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2273</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.2239</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2011-01-31 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>665 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     instant  season  yr  mnth  hr  holiday  weekday  \\\n",
       "2011-01-01 00:00:00        1       1   0     1   0        0        6   \n",
       "2011-01-01 01:00:00        2       1   0     1   1        0        6   \n",
       "2011-01-01 02:00:00        3       1   0     1   2        0        6   \n",
       "2011-01-01 03:00:00        4       1   0     1   3        0        6   \n",
       "2011-01-01 04:00:00        5       1   0     1   4        0        6   \n",
       "...                      ...     ...  ..   ...  ..      ...      ...   \n",
       "2011-01-30 20:00:00      661       1   0     1  20        0        0   \n",
       "2011-01-30 21:00:00      662       1   0     1  21        0        0   \n",
       "2011-01-30 22:00:00      663       1   0     1  22        0        0   \n",
       "2011-01-30 23:00:00      664       1   0     1  23        0        0   \n",
       "2011-01-31 00:00:00      665       1   0     1   0        0        1   \n",
       "\n",
       "                     workingday  weathersit  temp   atemp   hum  windspeed  \\\n",
       "2011-01-01 00:00:00           0           1  0.24  0.2879  0.81     0.0000   \n",
       "2011-01-01 01:00:00           0           1  0.22  0.2727  0.80     0.0000   \n",
       "2011-01-01 02:00:00           0           1  0.22  0.2727  0.80     0.0000   \n",
       "2011-01-01 03:00:00           0           1  0.24  0.2879  0.75     0.0000   \n",
       "2011-01-01 04:00:00           0           1  0.24  0.2879  0.75     0.0000   \n",
       "...                         ...         ...   ...     ...   ...        ...   \n",
       "2011-01-30 20:00:00           0           2  0.26  0.2727  0.65     0.1045   \n",
       "2011-01-30 21:00:00           0           2  0.24  0.2424  0.70     0.1642   \n",
       "2011-01-30 22:00:00           0           2  0.24  0.2273  0.70     0.1940   \n",
       "2011-01-30 23:00:00           0           2  0.24  0.2121  0.65     0.2836   \n",
       "2011-01-31 00:00:00           1           2  0.24  0.2273  0.65     0.2239   \n",
       "\n",
       "                     casual  registered  cnt          time_stamp  \n",
       "2011-01-01 00:00:00       3          13   16 2011-01-01 00:00:00  \n",
       "2011-01-01 01:00:00       8          32   40 2011-01-01 01:00:00  \n",
       "2011-01-01 02:00:00       5          27   32 2011-01-01 02:00:00  \n",
       "2011-01-01 03:00:00       3          10   13 2011-01-01 03:00:00  \n",
       "2011-01-01 04:00:00       0           1    1 2011-01-01 04:00:00  \n",
       "...                     ...         ...  ...                 ...  \n",
       "2011-01-30 20:00:00       3          30   33 2011-01-30 20:00:00  \n",
       "2011-01-30 21:00:00       3          25   28 2011-01-30 21:00:00  \n",
       "2011-01-30 22:00:00       2          19   21 2011-01-30 22:00:00  \n",
       "2011-01-30 23:00:00       5          16   21 2011-01-30 23:00:00  \n",
       "2011-01-31 00:00:00       1           6    7 2011-01-31 00:00:00  \n",
       "\n",
       "[665 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evidently.calculations.data_quality import get_features_stats\n",
    "from evidently.core import ColumnType\n",
    "from evidently.metrics.data_integrity.column_summary_metric import ColumnCharacteristics\n",
    "from evidently.metrics.data_integrity.column_summary_metric import FeatureQualityStats\n",
    "from evidently.metrics.data_integrity.column_summary_metric import NumericCharacteristics\n",
    "from evidently.metrics.data_integrity.column_summary_metric import CategoricalCharacteristics\n",
    "from evidently.metrics.data_integrity.column_summary_metric import DatetimeCharacteristics\n",
    "\n",
    "\n",
    "def map_data(stats: FeatureQualityStats) -> ColumnCharacteristics:\n",
    "    if stats.feature_type == \"num\":\n",
    "        if isinstance(stats.max, str) or isinstance(stats.min, str) or isinstance(stats.most_common_value, str):\n",
    "            raise ValueError(\"max / min stats should be int or float type, but got str\")\n",
    "        return NumericCharacteristics(\n",
    "            number_of_rows=stats.number_of_rows,\n",
    "            count=stats.count,\n",
    "            mean=stats.mean,\n",
    "            std=stats.std,\n",
    "            min=stats.min,\n",
    "            max=stats.max,\n",
    "            p25=stats.percentile_25,\n",
    "            p50=stats.percentile_50,\n",
    "            p75=stats.percentile_75,\n",
    "            unique=stats.unique_count,\n",
    "            unique_percentage=stats.unique_percentage,\n",
    "            missing=stats.missing_count,\n",
    "            missing_percentage=stats.missing_percentage,\n",
    "            infinite_count=stats.infinite_count,\n",
    "            infinite_percentage=stats.infinite_percentage,\n",
    "            most_common=stats.most_common_value,\n",
    "            most_common_percentage=stats.most_common_value_percentage,\n",
    "        )\n",
    "    if stats.feature_type == \"cat\":\n",
    "        return CategoricalCharacteristics(\n",
    "            number_of_rows=stats.number_of_rows,\n",
    "            count=stats.count,\n",
    "            unique=stats.unique_count,\n",
    "            unique_percentage=stats.unique_percentage,\n",
    "            most_common=stats.most_common_value,\n",
    "            most_common_percentage=stats.most_common_value_percentage,\n",
    "            missing=stats.missing_count,\n",
    "            missing_percentage=stats.missing_percentage,\n",
    "        )\n",
    "    if stats.feature_type == \"datetime\":\n",
    "        if not isinstance(stats.min, str) or not isinstance(stats.max, str):\n",
    "            raise ValueError(f\"min / max expected to be str for datetime, got {type(stats.min)}/{type(stats.max)}\")\n",
    "        return DatetimeCharacteristics(\n",
    "            number_of_rows=stats.number_of_rows,\n",
    "            count=stats.count,\n",
    "            unique=stats.unique_count,\n",
    "            unique_percentage=stats.unique_percentage,\n",
    "            most_common=stats.most_common_value,\n",
    "            most_common_percentage=stats.most_common_value_percentage,\n",
    "            missing=stats.missing_count,\n",
    "            missing_percentage=stats.missing_percentage,\n",
    "            first=stats.min,\n",
    "            last=stats.max,\n",
    "        )\n",
    "    raise ValueError(f\"unknown feature type {stats.feature_type}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "from typing import Dict\n",
    "def period_characteristic_table(data: Dict[str, Union[CategoricalCharacteristics, NumericCharacteristics]]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert a dictionary of characteristics into a DataFrame for display.\n",
    "    \n",
    "    Parameters:\n",
    "    - data: A dictionary where keys are period labels (e.g., '2011-01') and values are\n",
    "            characteristics dictionaries (e.g., 'CategoricalCharacteristics' or 'NumericCharacteristics').\n",
    "\n",
    "    Returns:\n",
    "    - A DataFrame with periods as columns and characteristics as rows.\n",
    "    \"\"\"\n",
    "    # Initialize an empty DataFrame\n",
    "    result_df = pd.DataFrame()\n",
    "    for key in data.keys():\n",
    "        data[key] = data[key].__dict__\n",
    "\n",
    "    # Process each period's characteristics\n",
    "    for period, characteristics in data.items():\n",
    "        # Format characteristics into a dictionary suitable for DataFrame\n",
    "        formatted_characteristics = {\n",
    "            key: (\n",
    "                f\"{value} ({characteristics[f'{key}_percentage']:.2f}%)\" \n",
    "                if f\"{key}_percentage\" in characteristics \n",
    "                else value\n",
    "            )\n",
    "            for key, value in characteristics.items()\n",
    "            if key not in ['type', 'unique_percentage', 'most_common_percentage', 'missing_percentage', 'infinite_percentage']\n",
    "        }\n",
    "        # Add to the result DataFrame\n",
    "        result_df[period] = pd.Series(formatted_characteristics)\n",
    "\n",
    "    # Set a proper index (characteristic names) and return\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>2021-09</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>number_of_rows</th>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>missing</th>\n",
       "      <td>0 (0.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p25</th>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p50</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>p75</th>\n",
       "      <td>0.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>23 (3.46%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infinite_count</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>most_common</th>\n",
       "      <td>0.16 (13.83%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      2021-09\n",
       "number_of_rows            665\n",
       "count                     665\n",
       "missing             0 (0.00%)\n",
       "mean                      0.2\n",
       "std                      0.08\n",
       "min                      0.02\n",
       "p25                      0.16\n",
       "p50                       0.2\n",
       "p75                      0.24\n",
       "max                      0.46\n",
       "unique             23 (3.46%)\n",
       "infinite_count              0\n",
       "most_common     0.16 (13.83%)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = map_data(get_features_stats(reference['temp'], ColumnType.Numerical))\n",
    "period_characteristic_table({'2021-09': a})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "def calculate_characteristic(data_chunks: Dict[str, pd.DataFrame], col_name: str, col_type: str)-> Dict[str, pd.DataFrame]:\n",
    "    feature_stat_dict = {}\n",
    "    if col_type == 'num':\n",
    "        col_type = ColumnType.Numerical\n",
    "        index_name_mapping = {\n",
    "            \"number_of_rows\": \"number of rows\",\n",
    "            \"count\": \"count\",\n",
    "            \"missing\": \"missing\",\n",
    "            \"mean\": \"mean\",\n",
    "            \"std\": \"std\",\n",
    "            \"min\": \"min\",\n",
    "            \"p25\": \"25%\",\n",
    "            \"p50\": \"50%\",\n",
    "            \"p75\": \"75%\",\n",
    "            \"max\": \"max\",\n",
    "            \"unique\": \"unique\",\n",
    "            \"most_common\": \"most common\",\n",
    "            \"missing_percentage\": \"missing\",\n",
    "            \"infinite_count\": \"infinite\",\n",
    "            \"infinite_percentage\": \"infinite\",\n",
    "        }\n",
    "    elif col_type == 'cat':\n",
    "        col_type = ColumnType.Categorical\n",
    "        index_name_mapping = {\n",
    "            \"number_of_rows\": \"count\",\n",
    "            \"count\": \"count\",\n",
    "            \"missing\": \"missing\",\n",
    "            \"unique\": \"unique\",\n",
    "            \"most_common\": \"most common\"\n",
    "        }\n",
    "    else:\n",
    "        raise ValueError(\"col_type must be 'cat' or 'num'\")\n",
    "    for key in data_chunks.keys():\n",
    "        feature_stat_dict[key] = map_data(get_features_stats(data_chunks[key][col_name], col_type))\n",
    "    result = period_characteristic_table(feature_stat_dict)\n",
    "    result.rename(index=index_name_mapping, inplace=True)\n",
    "    if col_type == ColumnType.Categorical:\n",
    "        result.drop(['new_in_current_values_count', 'unused_in_current_values_count'], axis=0, inplace=True)\n",
    "    return result "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_chunks_dict = divide_into_chunks_by_period(current, time_column=column_mapping.datetime_features, period='M')\n",
    "ref_chunks_dict = divide_into_chunks_by_period(reference, time_column=column_mapping.datetime_features, period='M')\n",
    "ref = calculate_characteristic(ref_chunks_dict, 'temp', 'cat')\n",
    "cur = calculate_characteristic(cur_chunks_dict, 'temp', 'cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>2011-01</th>\n",
       "      <th>2011-02</th>\n",
       "      <th>2011-03</th>\n",
       "      <th>2011-04</th>\n",
       "      <th>2011-05</th>\n",
       "      <th>2011-06</th>\n",
       "      <th>2011-07</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>count</td>\n",
       "      <td>665</td>\n",
       "      <td>649</td>\n",
       "      <td>730</td>\n",
       "      <td>719</td>\n",
       "      <td>744</td>\n",
       "      <td>720</td>\n",
       "      <td>672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>missing</td>\n",
       "      <td>0 (0.00%)</td>\n",
       "      <td>0 (0.00%)</td>\n",
       "      <td>0 (0.00%)</td>\n",
       "      <td>0 (0.00%)</td>\n",
       "      <td>0 (0.00%)</td>\n",
       "      <td>0 (0.00%)</td>\n",
       "      <td>0 (0.00%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>most common</td>\n",
       "      <td>0.16 (13.83%)</td>\n",
       "      <td>0.22 (10.32%)</td>\n",
       "      <td>0.34 (11.10%)</td>\n",
       "      <td>0.46 (7.65%)</td>\n",
       "      <td>0.52 (10.22%)</td>\n",
       "      <td>0.7 (10.97%)</td>\n",
       "      <td>0.7 (11.61%)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>unique</td>\n",
       "      <td>23 (3.46%)</td>\n",
       "      <td>31 (4.78%)</td>\n",
       "      <td>30 (4.11%)</td>\n",
       "      <td>27 (3.76%)</td>\n",
       "      <td>29 (3.90%)</td>\n",
       "      <td>24 (3.33%)</td>\n",
       "      <td>20 (2.98%)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      2011-01        2011-02        2011-03       2011-04  \\\n",
       "0        count            665            649            730           719   \n",
       "4      missing      0 (0.00%)      0 (0.00%)      0 (0.00%)     0 (0.00%)   \n",
       "5  most common  0.16 (13.83%)  0.22 (10.32%)  0.34 (11.10%)  0.46 (7.65%)   \n",
       "6       unique     23 (3.46%)     31 (4.78%)     30 (4.11%)    27 (3.76%)   \n",
       "\n",
       "         2011-05       2011-06       2011-07  \n",
       "0            744           720           672  \n",
       "4      0 (0.00%)     0 (0.00%)     0 (0.00%)  \n",
       "5  0.52 (10.22%)  0.7 (10.97%)  0.7 (11.61%)  \n",
       "6     29 (3.90%)    24 (3.33%)    20 (2.98%)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.merge(left=ref, right=cur, left_index=True, right_index=True) \\\n",
    "    .reset_index() \\\n",
    "    .rename({'index': ''}, axis=1) \\\n",
    "    .drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from source.mlops_observation.utils.visualization import dataframe_to_widget\n",
    "# from source.mlops_observation.utils.data_quality import calculate_characteristic\n",
    "# from source.mlops_observation.utils.data_operations import divide_into_chunks_by_period\n",
    "# from evidently.base_metric import Metric\n",
    "# from evidently.base_metric import MetricResult\n",
    "# from evidently.base_metric import InputData\n",
    "# from evidently.renderers.html_widgets import BaseWidgetInfo\n",
    "# from evidently.renderers.html_widgets import header_text\n",
    "# from evidently.renderers.base_renderer import MetricRenderer\n",
    "# from evidently.renderers.base_renderer import default_renderer\n",
    "# from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class PeriodFeatureQualityResult(MetricResult):\n",
    "#     class Config:\n",
    "#         type_alias = \"evidently:metric_result:PeriodFeatureQualityResult\"\n",
    "#     num_feature_stats: Dict[str, pd.DataFrame]     # {col_name, stats}\n",
    "#     cat_feature_stats: Dict[str, pd.DataFrame]     # {col_name, stats}\n",
    "\n",
    "# class PeriodFeatureQualityMetric(Metric[PeriodFeatureQualityResult]):\n",
    "#     \"\"\"\n",
    "#     time_period (str): Offset aliases https://pandas.pydata.org/docs/user_guide/timeseries.html#dateoffset-objects\n",
    "#     \"\"\"\n",
    "#     class Config:\n",
    "#         type_alias = \"evidently:metric:PeriodFeatureQualityMetric\"\n",
    "#     _time_period: str\n",
    "#     def __init__(self, time_period: str = 'M'):\n",
    "#         self._time_period = time_period\n",
    "#         super().__init__()\n",
    "\n",
    "#     def calculate(self, data: InputData):\n",
    "#         num_feature_stats = {}\n",
    "#         cat_feature_stats = {}\n",
    "#         column_mapping = data.column_mapping\n",
    "#         if column_mapping.datetime_features is None:\n",
    "#             raise ValueError('column_mapping.datetime_features can not be None')\n",
    "#         if data.reference_data is not None:\n",
    "#             reference_chunks_dict = divide_into_chunks_by_period(data.reference_data, time_column=column_mapping.datetime_features, period=self._time_period)\n",
    "            \n",
    "#         current_chunks_dict = divide_into_chunks_by_period(data.current_data, time_column=column_mapping.datetime_features, period=self._time_period)\n",
    "#         if column_mapping.numerical_features is not None:\n",
    "#             for num_col in column_mapping.numerical_features:\n",
    "#                 current_stats = calculate_characteristic(current_chunks_dict, num_col, 'num')\n",
    "#                 if data.reference_data is not None:\n",
    "#                     reference_stats = calculate_characteristic(reference_chunks_dict, num_col, 'num')\n",
    "#                     reference_stats.columns = [f\"{col} (base)\" for col in reference_stats.columns]\n",
    "#                     num_feature_stats[num_col] = pd.merge(reference_stats, current_stats, left_index=True, right_index=True) \\\n",
    "#                         .reset_index() \\\n",
    "#                         .rename({'index': ''}, axis=1)\n",
    "#                 else:\n",
    "#                     num_feature_stats[num_col] = current_stats \\\n",
    "#                         .reset_index() \\\n",
    "#                         .rename({'index': ''}, axis=1)\n",
    "        \n",
    "#         if column_mapping.categorical_features is not None:\n",
    "#             for cat_col in column_mapping.categorical_features:\n",
    "#                 current_stats = calculate_characteristic(current_chunks_dict, cat_col, 'cat')\n",
    "#                 if data.reference_data is not None:\n",
    "#                     reference_stats = calculate_characteristic(reference_chunks_dict, cat_col, 'cat')\n",
    "#                     reference_stats.columns = [f\"{col} (base)\" for col in reference_stats.columns]\n",
    "#                     cat_feature_stats[cat_col] = pd.merge(reference_stats, current_stats, left_index=True, right_index=True) \\\n",
    "#                         .reset_index() \\\n",
    "#                         .rename({'index': ''}, axis=1) \\\n",
    "#                         .drop_duplicates()\n",
    "#                 else:\n",
    "#                     cat_feature_stats[cat_col] = current_stats \\\n",
    "#                         .reset_index() \\\n",
    "#                         .rename({'index': ''}, axis=1) \\\n",
    "#                         .drop_duplicates()\n",
    "        \n",
    "#         return PeriodFeatureQualityResult(\n",
    "#             num_feature_stats=num_feature_stats,\n",
    "#             cat_feature_stats=cat_feature_stats\n",
    "#         )\n",
    "\n",
    "\n",
    "# from evidently.renderers.html_widgets import ColumnDefinition\n",
    "# from evidently.renderers.html_widgets import RichTableDataRow\n",
    "# from evidently.renderers.html_widgets import RowDetails\n",
    "# from evidently.renderers.html_widgets import rich_table_data\n",
    "# from evidently.renderers.html_widgets import rich_table_data\n",
    "# from typing import Optional\n",
    "# @default_renderer(wrap_type=PeriodFeatureQualityMetric)\n",
    "# class PeriodFeatureQualityRender(MetricRenderer):\n",
    "#     def _generate_column_params(\n",
    "#         self,\n",
    "#         column_data: pd.DataFrame\n",
    "#         )-> Optional[RichTableDataRow]:\n",
    "#         details = RowDetails()\n",
    "#         # -----------------------------------------\n",
    "#         table = column_data\n",
    "#         table = dataframe_to_widget(table)\n",
    "#         details.with_part(\"STAT TABLE\", info=table)\n",
    "#         # -----------------------------------------\n",
    "        \n",
    "#         return RichTableDataRow({\n",
    "#             \"column_name\": column_data.col_name, \n",
    "#             \"column_type\": column_data.col_type,\n",
    "#             \"period_drifted_count\": fr\"{column_data.period_drifted_count}/{column_data.period_count}\"\n",
    "#             }, \n",
    "#             details=details)\n",
    "#     def render_html(self, obj: PeriodFeatureQualityMetric) -> List[BaseWidgetInfo]:\n",
    "#         results = obj.get_result()\n",
    "#         color_options = self.color_options\n",
    "#         rows = []\n",
    "#         # summary_table = dataframe_to_widget(results.summary_table)\n",
    "#         for cat_col in results.cat_feature_stats.keys():\n",
    "#             details = RowDetails()\n",
    "#             table = dataframe_to_widget(results.cat_feature_stats[cat_col])\n",
    "#             details.with_part(\"STAT TABLE\", info=table)\n",
    "#             rows.append(RichTableDataRow({\n",
    "#                 \"column_name\": cat_col, \n",
    "#                 \"column_type\": 'cat'}, \n",
    "#                 details=details))\n",
    "#         for num_col in results.num_feature_stats.keys():\n",
    "#             details = RowDetails()\n",
    "#             table = dataframe_to_widget(results.num_feature_stats[num_col])\n",
    "#             details.with_part(\"STAT TABLE\", info=table)\n",
    "#             rows.append(RichTableDataRow({\n",
    "#                 \"column_name\": num_col, \n",
    "#                 \"column_type\": 'num'}, \n",
    "#                 details=details))\n",
    "#         columns = [\n",
    "#             ColumnDefinition(\"Column Name\", \"column_name\"),\n",
    "#             ColumnDefinition(\"Type\", \"column_type\")\n",
    "#         ]\n",
    "#         return [\n",
    "#             header_text(label=f\"Feature Statistic in Period\"),\n",
    "#             rich_table_data(\n",
    "#                 columns=columns,\n",
    "#                 data=rows\n",
    "#             )\n",
    "#         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from source.mlops_observation import Report\n",
    "from source.mlops_observation.metrics import PeriodDataQualityMetric\n",
    "from source.mlops_observation.metrics import PeriodDataDriftMetric\n",
    "from source.mlops_observation.metrics import PeriodFeatureQualityMetric\n",
    "report = Report([\n",
    "    PeriodDataDriftMetric(time_period='M'),\n",
    "    PeriodDataQualityMetric(time_period='M'),\n",
    "    PeriodFeatureQualityMetric(time_period='M'),\n",
    "    ])\n",
    "report.run(reference_data=None, current_data=current, column_mapping=column_mapping)\n",
    "report.save_html('1.html')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "207e60eac2ff56558166198e2c0941ea4216ea025c42ddd95d3a76ed9cb3f5a9"
  },
  "kernelspec": {
   "display_name": "Python 3.10.15 ('model-monitoring')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
